#!/usr/bin/env python
# -*- tab-width:4;indent-tabs-mode:t;show-trailing-whitespace:t;rm-trailing-spaces:t -*-
# vi: set ts=2 noet:

import sys
import argparse

import pandas as pd
import pyarrow.parquet
import pyarrow as pa
import joblib
from MPLearn import embedding
import hdbscan

DESCRIPTION="""Do the embedding for one dataset with one set of parameters
version 0.0.1

Example:
Fit and embed the full cell features matrix:

    cd MPLearn/vignettes/Steatosis2020/umap_embedding_200217
    python scripts/umap_embedding.py \
        --dataset intermediate_data/cf10k.parquet \
        --tag cell_features_pca_umap2_15_0.0 \
        --umap_n_components 2 \
        --umap_n_neighbors 15 \
        --umap_min_dist 0.0

Embed a 10k subset of cell features given a reference embedding:

    cd MPLearn/vignettes/Steatosis2020/umap_embedding_200217
    python scripts/umap_embedding.py \
        --dataset intermediate_data/cf10k.parquet \
        --tag cf10k_pca_umap2_15_0.0_euclid \
        --ref_embed_dir intermediate_data/cell_features_pca_umap2_15_0.0

"""

def main(argv):
    parser = argparse.ArgumentParser(description=DESCRIPTION)
    parser.add_argument(
        "--dataset", type=str, action="store", dest="dataset",
        help="""Path to a parquet table on disk""")
    parser.add_argument(
        "--tag", type=str, action="store", dest="tag",
        help="""Identifier for embedding""")
    parser.add_argument(
        "--ref_embed_dir", type=str, action="store", dest="ref_embed_dir", default=None,
        help="""Directory of previously computed embedding to use to re-embed the given dataset.""")
    parser.add_argument(
        "--pca_n_components", type=int, action="store", dest="pca_n_components", default=None,
        help="""Dimension of the preliminary PCA embedding""")
    parser.add_argument(
        "--umap_n_components", type=int, action="store", dest="umap_n_components", default=None,
        help="""Dimension of the resulting UMAP embedding""")
    parser.add_argument(
        "--umap_n_neighbors", type=int, action="store", dest="umap_n_neighbors", default=15,
        help="""Number of neighbors when computing UMAP embedding""")
    parser.add_argument(
        "--umap_min_dist", type=float, action="store", dest="umap_min_dist", default=0.0,
        help="""Minimum distance between points in UMAP embedding""")
    parser.add_argument(
        "--umap_init", type=str, action="store", dest="umap_init", default='spectral',
        help="""UMAP initialization. Spectral is prefered, but random is more robust""")
    parser.add_argument(
        "--hbscan_min_cluster_size", type=int, action="store", dest="hbscan_min_cluster_size", default=100,
        help="""HBSCAN minimum cluster size""")
    parser.add_argument(
        "--compute_hdbscan_clusters", type=bool, action="store", dest="compute_hbscan_clusters", default=True,
        help="""Compute HBSCAN clusters and store in the tagged directory""")
    parser.add_argument(
        "--seed", type=int, action="store", dest="seed", default=14730219,
        help="""Initialize random state with this seed. Default is Nicolaus Copernicus' birthday""")
    parser.add_argument(
        "--verbose", type=bool, action="store", dest="verbose", default=False,
        help="""Verbose output""")

    arguments = parser.parse_args()

    dataset = pa.parquet.read_table(source=arguments.dataset).to_pandas()

    if arguments.ref_embed_dir is not None:
        if arguments.verbose:
            print("Emebedding dataset in reference UMAP {} ...".format(arguments.ref_embed_dir))

        umap_embedding = embedding.embed(
            dataset=dataset,
            embed_dir="intermediate_data/{}".format(arguments.tag),
            ref_embed_dir="{}".format(arguments.ref_embed_dir),
            verbose=arguments.verbose)
    else:
        if arguments.verbose:
            print("Computing UMAP embedding ...")

        umap_embedding = embedding.fit_embedding(
            dataset=dataset,
            embed_dir="intermediate_data/{}".format(arguments.tag),
            pca_n_components=arguments.pca_n_components,
            umap_n_components=arguments.umap_n_components,
            umap_init=arguments.umap_init,
            umap_n_neighbors=arguments.umap_n_neighbors,
            umap_min_dist=arguments.umap_min_dist,
            seed=arguments.seed,
            verbose=arguments.verbose)

    embedding.plot_embedding(
        embedding=umap_embedding,
        output_fname="product/figures/{}_embedding.png".format(arguments.tag))

    if arguments.compute_hbscan_clusters:
        if arguments.verbose:
            print("Computing HBSCAN clusters ...")
        clusterer = hdbscan.HDBSCAN(min_cluster_size=arguments.hbscan_min_cluster_size)
        cluster_labels = clusterer.fit_predict(umap_embedding)
        cluster_labels = pd.DataFrame(cluster_labels, columns=['cluster_label'])
        joblib.dump(
            value=clusterer,
            filename="intermediate_data/{}/hdbscan_clusterer_min{}.joblib".format(
                arguments.tag, arguments.hbscan_min_cluster_size ))
        pa.parquet.write_table(
            table=pa.Table.from_pandas(cluster_labels),
            where="intermediate_data/{}/hdbscan_clustering_min{}.parquet".format(arguments.tag, arguments.hbscan_min_cluster_size))

if __name__ == "__main__":
    main(sys.argv)
